"""
Scraper espec√≠fico para Creative C√≥pias
Implementa m√©todos de extra√ß√£o para https://www.creativecopias.com.br
"""

from typing import Dict, List, Optional, Any
from bs4 import BeautifulSoup
import requests
import re
from loguru import logger
from .scraper_base import ScraperBase

class CreativeScraper(ScraperBase):
    """Scraper espec√≠fico para Creative C√≥pias"""
    
    def __init__(self, delay_range: tuple = (2, 4), timeout: int = 30):
        """
        Inicializa scraper do Creative C√≥pias
        
        Args:
            delay_range: Delay entre requests (2-4 segundos)
            timeout: Timeout para requests
        """
        super().__init__(delay_range, timeout)
        self.base_url = "https://www.creativecopias.com.br"
        
        # Headers espec√≠ficos para Creative C√≥pias (sem User-Agent espec√≠fico)
        # Criar nova sess√£o limpa para evitar headers herdados
        self.session.close()
        self.session = requests.Session()
            
        self.session.headers.update({
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        logger.info("üöÄ Creative Scraper inicializado")
    
    def load_page(self, url: str) -> Optional[BeautifulSoup]:
        """
        Carrega p√°gina da Creative C√≥pias
        
        Args:
            url: URL para carregar
            
        Returns:
            BeautifulSoup object ou None se erro
        """
        try:
            logger.info(f"üìÑ Carregando p√°gina: {url}")
            
            # Usar requests simples sem User-Agent espec√≠fico (funciona melhor com Creative C√≥pias)
            response = requests.get(url, timeout=self.timeout)
            
            # Verificar se p√°gina carregou corretamente
            if "creative" not in response.text.lower():
                logger.warning(f"‚ö†Ô∏è P√°gina pode n√£o ter carregado corretamente: {url}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            logger.debug(f"‚úÖ P√°gina carregada com sucesso: {len(response.content)} bytes")
            
            return soup
            
        except requests.RequestException as e:
            logger.error(f"‚ùå Erro de rede ao carregar {url}: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar p√°gina {url}: {e}")
            return None
    
    def parse_product_list(self, html: BeautifulSoup) -> List[Any]:
        """
        Extrai elementos de produtos da p√°gina
        
        Args:
            html: BeautifulSoup da p√°gina
            
        Returns:
            Lista de elementos de produtos
        """
        try:
            products = []
            
            logger.info("üîç Iniciando parse_product_list...")
            
            # Primeiro, buscar especificamente por elementos com .product-name (detectado na an√°lise)
            product_names = html.select('.product-name')
            logger.info(f"üì¶ Busca por .product-name retornou {len(product_names)} elementos")
            
            if product_names:
                logger.info(f"üì¶ Encontrados {len(product_names)} elementos .product-name")
                for i, name_elem in enumerate(product_names):
                    logger.debug(f"  [{i+1}] Processando: {name_elem.get_text(strip=True)[:50]}...")
                    # Pegar o container pai do produto
                    parent = name_elem.find_parent(['li', 'div', 'article'])
                    if parent and parent not in products:
                        products.append(parent)
                        logger.debug(f"      ‚úÖ Produto {i+1} adicionado")
            
            if products:
                logger.info(f"üì¶ {len(products)} produtos encontrados via .product-name")
                logger.info(f"üéØ Total de {len(products)} produtos prontos para extra√ß√£o")
                return products
            
            # Se n√£o encontrou, tenta seletores espec√≠ficos
            selectors = [
                '.products-grid .item',  # Magento products grid items
                '.category-products .item',  # Magento category products
                '.product-item',  # Padr√£o Magento 2
                '.item .product-name',  # Items com product name dentro
                '.product',
                '.item-product',
                '[data-product]',
                '.card-product',
                '.product-card',
                '.showcase-item',
                'li[id*="product"]',
                '.vitrine-produto',
                '.produto-item'
            ]
            
            for selector in selectors:
                elements = html.select(selector)
                if elements:
                    logger.info(f"üì¶ Encontrados {len(elements)} produtos usando seletor: {selector}")
                    # Filtrar elementos que realmente parecem produtos
                    valid_products = []
                    for element in elements:
                        # Verificar se tem caracter√≠sticas de produto
                        has_name = element.select_one('.product-name, h2, h3, a[title]')
                        has_price = element.select_one('.price-box, .price, .preco')
                        has_link = element.select_one('a[href]')
                        
                        if has_name or has_price or has_link:
                            valid_products.append(element)
                    
                    if valid_products:
                        logger.info(f"‚úÖ {len(valid_products)} produtos v√°lidos encontrados com {selector}")
                        products.extend(valid_products)
                        break
            
            # Se n√£o encontrou com seletores espec√≠ficos, tenta busca mais gen√©rica
            if not products:
                # Buscar por links que contenham palavras relacionadas a produtos
                links = html.find_all('a', href=True)
                product_links = []
                
                for link in links:
                    href = link.get('href', '')
                    text = link.get_text(strip=True).lower()
                    
                    # Verificar se √© link de produto baseado na URL ou texto
                    if any(keyword in href.lower() for keyword in ['produto', 'item', '/p/', '/product']):
                        product_links.append(link.parent or link)
                    elif any(keyword in text for keyword in ['impressora', 'multifuncional', 'toner', 'cartucho']):
                        product_links.append(link.parent or link)
                
                products = list(set(product_links))  # Remove duplicatas
                
                if products:
                    logger.info(f"üì¶ Encontrados {len(products)} produtos via busca gen√©rica")
            
            # Se ainda n√£o encontrou, buscar por imagens de produtos
            if not products:
                img_elements = html.find_all('img', src=True)
                for img in img_elements:
                    src = img.get('src', '').lower()
                    alt = img.get('alt', '').lower()
                    
                    if any(keyword in src for keyword in ['produto', 'product', 'item']) or \
                       any(keyword in alt for keyword in ['impressora', 'multifuncional', 'toner']):
                        parent = img.find_parent(['div', 'li', 'article', 'section'])
                        if parent:
                            products.append(parent)
                
                products = list(set(products))  # Remove duplicatas
                
                if products:
                    logger.info(f"üì¶ Encontrados {len(products)} produtos via an√°lise de imagens")
            
            if not products:
                logger.warning("‚ö†Ô∏è Nenhum produto encontrado na p√°gina")
                # Debug: salvar HTML para an√°lise
                with open('logs/debug_page.html', 'w', encoding='utf-8') as f:
                    f.write(str(html))
                logger.info("üîç HTML da p√°gina salvo em logs/debug_page.html para an√°lise")
            else:
                logger.info(f"üéØ Total de {len(products)} produtos prontos para extra√ß√£o")
            
            return products
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair lista de produtos: {e}")
            return []
    
    def extract_product_data(self, product_element: Any) -> Dict[str, Any]:
        """
        Extrai dados de um produto espec√≠fico
        
        Args:
            product_element: Elemento HTML do produto
            
        Returns:
            Dicion√°rio com dados do produto
        """
        try:
            product_data = {}
            
            # Extrair nome do produto
            name = self._extract_product_name(product_element)
            if not name:
                return {}  # Nome √© obrigat√≥rio
            
            product_data['nome'] = name
            
            # Extrair URL do produto
            url = self._extract_product_url(product_element)
            product_data['url'] = url
            
            # Extrair pre√ßo
            price = self._extract_product_price(product_element)
            product_data['preco'] = price
            
            # Extrair c√≥digo do produto
            codigo = self._extract_product_code(product_element)
            product_data['codigo'] = codigo
            
            # Extrair marca
            marca = self._extract_product_brand(product_element)
            product_data['marca'] = marca
            
            # Extrair descri√ß√£o
            descricao = self._extract_product_description(product_element)
            product_data['descricao'] = descricao
            
            # Extrair imagem
            imagem = self._extract_product_image(product_element)
            product_data['imagem'] = imagem
            
            # Extrair disponibilidade
            disponivel = self._extract_product_availability(product_element)
            product_data['disponivel'] = disponivel
            
            logger.debug(f"‚úÖ Dados extra√≠dos para: {name}")
            return product_data
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair dados do produto: {e}")
            return {}
    
    def _extract_product_name(self, element: Any) -> Optional[str]:
        """Extrai nome do produto"""
        selectors = [
            'h3', 'h2', 'h4',
            '.product-name', '.nome-produto', '.title',
            '[data-name]', '.product-title',
            'a[title]'
        ]
        
        for selector in selectors:
            try:
                found = element.select_one(selector)
                if found:
                    text = found.get_text(strip=True)
                    if len(text) > 3:  # Nome v√°lido deve ter mais de 3 caracteres
                        return text
                    
                # Tentar atributo title
                if hasattr(found, 'get') and found.get('title'):
                    return found.get('title').strip()
            except:
                continue
        
        # √öltima tentativa: pegar primeiro texto significativo
        text = element.get_text(strip=True)
        if text and len(text) > 3:
            # Pegar primeira linha que pare√ßa um nome de produto
            lines = text.split('\n')
            for line in lines:
                line = line.strip()
                if len(line) > 10 and not line.startswith('R$'):
                    return line
        
        return None
    
    def _extract_product_url(self, element: Any) -> Optional[str]:
        """Extrai URL do produto"""
        try:
            # Buscar link dentro do elemento
            link = element.find('a', href=True)
            if link:
                href = link.get('href')
                
                # Se for URL relativa, adicionar dom√≠nio
                if href.startswith('/'):
                    return self.base_url + href
                elif href.startswith('http'):
                    return href
                else:
                    return self.base_url + '/' + href
        except:
            pass
        
        return None
    
    def _extract_product_price(self, element: Any) -> Optional[str]:
        """Extrai pre√ßo do produto"""
        price_selectors = [
            '.price', '.preco', '.valor',
            '[data-price]', '.product-price',
            '.money', '.currency'
        ]
        
        for selector in price_selectors:
            try:
                price_elem = element.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    # Extrair n√∫meros e v√≠rgulas/pontos do pre√ßo
                    price_match = re.search(r'R\$[\s]*([0-9.,]+)', price_text)
                    if price_match:
                        return f"R$ {price_match.group(1)}"
            except:
                continue
        
        # Busca mais gen√©rica por padr√£o de pre√ßo
        text = element.get_text()
        price_pattern = r'R\$[\s]*([0-9.,]+)'
        match = re.search(price_pattern, text)
        if match:
            return f"R$ {match.group(1)}"
        
        return None
    
    def _extract_product_code(self, element: Any) -> Optional[str]:
        """Extrai c√≥digo do produto"""
        try:
            text = element.get_text()
            
            # Padr√µes comuns de c√≥digo
            patterns = [
                r'C√≥digo[:\s]*([A-Z0-9\-]+)',
                r'Ref[:\s]*([A-Z0-9\-]+)',
                r'SKU[:\s]*([A-Z0-9\-]+)',
                r'Item[:\s]*([A-Z0-9\-]+)'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    return match.group(1)
        except:
            pass
        
        return None
    
    def _extract_product_brand(self, element: Any) -> Optional[str]:
        """Extrai marca do produto"""
        try:
            brand_selectors = [
                '.brand', '.marca', '.fabricante',
                '[data-brand]', '.manufacturer'
            ]
            
            for selector in brand_selectors:
                brand_elem = element.select_one(selector)
                if brand_elem:
                    return brand_elem.get_text(strip=True)
            
            # Buscar marcas conhecidas no texto
            text = element.get_text().lower()
            brands = ['hp', 'canon', 'epson', 'brother', 'samsung', 'lexmark', 'xerox', 'ricoh']
            
            for brand in brands:
                if brand in text:
                    return brand.upper()
        except:
            pass
        
        return None
    
    def _extract_product_description(self, element: Any) -> Optional[str]:
        """Extrai descri√ß√£o do produto"""
        try:
            desc_selectors = [
                '.description', '.descricao', '.resumo',
                '.product-description', '.summary'
            ]
            
            for selector in desc_selectors:
                desc_elem = element.select_one(selector)
                if desc_elem:
                    desc = desc_elem.get_text(strip=True)
                    if len(desc) > 20:  # Descri√ß√£o v√°lida deve ser mais longa
                        return desc[:200]  # Limitar tamanho
        except:
            pass
        
        return None
    
    def _extract_product_image(self, element: Any) -> Optional[str]:
        """Extrai URL da imagem do produto"""
        try:
            img = element.find('img')
            if img:
                src = img.get('src') or img.get('data-src')
                if src:
                    # Se for URL relativa, adicionar dom√≠nio
                    if src.startswith('/'):
                        return self.base_url + src
                    elif src.startswith('http'):
                        return src
        except:
            pass
        
        return None
    
    def _extract_product_availability(self, element: Any) -> bool:
        """Verifica se produto est√° dispon√≠vel"""
        try:
            text = element.get_text().lower()
            
            # Palavras que indicam indisponibilidade
            unavailable_words = ['indispon√≠vel', 'esgotado', 'fora de estoque', 'sem estoque']
            
            for word in unavailable_words:
                if word in text:
                    return False
            
            # Se encontrar bot√£o de comprar, provavelmente est√° dispon√≠vel
            buy_button = element.find(['button', 'a'], text=re.compile(r'comprar|adicionar', re.I))
            if buy_button:
                return True
                
        except:
            pass
        
        # Assumir dispon√≠vel por padr√£o
        return True 
 
 
 
 